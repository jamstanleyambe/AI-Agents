{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c67978eb-73eb-4dc3-a05d-4cc4302870d6",
   "metadata": {},
   "source": [
    "# State altering agents: stand up comedy\n",
    "\n",
    "In this example, we are going to create two agents. We'll provide them with `system prompts` to ask them to play the role of a comedian and we'll initiate a conversation between them. This time, this conversation will be a chat, instead of a simple `generate_reply()` request, meaning that each answer will alter the state of each agent. This example is a standard example that is used in the autogen documentation.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8262c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Get the API key\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc2e04d2-0ad5-460f-a69d-69b1ef19744e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll always have to start by creating a llm_config object to configure our agents\n",
    "llm_config = {\n",
    "    \"model\": \"gpt-3.5-turbo\", \n",
    "    \"api_key\": \"api_key\",\n",
    "    \"cache\": None\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb4b3c1-0bb3-42a6-984e-b21dc7edd8aa",
   "metadata": {},
   "source": [
    "## Conversable Agent\n",
    "\n",
    "Let's important the ConversableAgent class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93821754-9458-4195-8b8f-9beebcfb74ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3550813-4331-4ebd-a635-d86396147e6c",
   "metadata": {},
   "source": [
    "Let us now define our agents, we'll give them names, our chatGPT3.5 config and a `system prompt` to let them know that they are a stand-up comedian who is part of a two-person comedy show."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6afd6b1-2de9-47d1-a01c-e691df4e7a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "bret = ConversableAgent(\n",
    "    name=\"Bret\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"Your name is Bret and you are a stand-up comedian in a two-person comedy show.\",\n",
    ")\n",
    "jemaine = ConversableAgent(\n",
    "    name=\"Jemaine\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"Your name is Jemain and you are a stand-up comedian in a two-person comedy show.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce891250-e327-4e14-9ff9-a37bfba47203",
   "metadata": {},
   "source": [
    "And now that we have our agents, we can start a chat between them. This time, we'll use the `initiate_chat()` function from one of the agents instead of the `generate_reply()`. This function will require a receiver and an initiation message. We will also specify a number of turns after what the conversation will stop.  \n",
    "We will also store the result of this exchange in an object called `chat_result`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ca72f47-74ba-4066-9ca7-16546835ac07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mBret\u001b[0m (to Jemaine):\n",
      "\n",
      "Jemaine, tell me a joke.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mJemaine\u001b[0m (to Bret):\n",
      "\n",
      "Sure! Why did the scarecrow win an award? Because he was outstanding in his field!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mBret\u001b[0m (to Jemaine):\n",
      "\n",
      "Nice one, Jemaine! Now, I've got a joke for you. Why did the math book look sad? Because it had too many problems!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mJemaine\u001b[0m (to Bret):\n",
      "\n",
      "Haha, that's a good one! I guess that book could use some cheering up!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chat_result = bret.initiate_chat(\n",
    "    recipient = jemaine,\n",
    "    message=\"Jemaine, tell me a joke.\", \n",
    "    max_turns=2 # The conversation will stop after each agent has spoken twice\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61219955-8237-4675-a912-44b479f63b5c",
   "metadata": {},
   "source": [
    "You should have been able to read an exchange between the two agents! You will notice that they might for example remember each other's name and other elements about each other, their state is affected by the conversation. This is your first conversation between LLM agents, congrats!  \n",
    "You can have some fun if you'd like by creating two different agents, give them different roles, historical ones, different setups and let them talk to practice.  \n",
    "\n",
    "## Better explore chat results\n",
    "\n",
    "During this exchange, the only element we received is the chat exchange. We might want to further explore it. We can do so using the following elements.\n",
    "\n",
    "We are going to import the `pprint` standard library from python to display somee elements of the chat exchange. We can start by displaying the chat history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b24b8910-4d72-4803-899a-5885685ad283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'Jemaine, tell me a joke.', 'role': 'assistant'},\n",
      " {'content': 'Sure! Why did the scarecrow win an award? Because he was '\n",
      "             'outstanding in his field!',\n",
      "  'role': 'user'},\n",
      " {'content': \"Nice one, Jemaine! Now, I've got a joke for you. Why did the \"\n",
      "             'math book look sad? Because it had too many problems!',\n",
      "  'role': 'assistant'},\n",
      " {'content': \"Haha, that's a good one! I guess that book could use some \"\n",
      "             'cheering up!',\n",
      "  'role': 'user'}]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "pprint.pprint(chat_result.chat_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa187180-7f5e-46b5-ac8f-f93c13d625bc",
   "metadata": {},
   "source": [
    "This gives us the whole exchange in a structured format that can be exported or re-used elsewhere in our program.\n",
    "\n",
    "We can also get a summary of how much this chat has cost us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad3a4a01-5405-446a-a813-19940a61b413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'usage_excluding_cached_inference': {'gpt-3.5-turbo-0125': {'completion_tokens': 70,\n",
      "                                                             'cost': 0.00020400000000000003,\n",
      "                                                             'prompt_tokens': 198,\n",
      "                                                             'total_tokens': 268},\n",
      "                                      'total_cost': 0.00020400000000000003},\n",
      " 'usage_including_cached_inference': {'gpt-3.5-turbo-0125': {'completion_tokens': 70,\n",
      "                                                             'cost': 0.00020400000000000003,\n",
      "                                                             'prompt_tokens': 198,\n",
      "                                                             'total_tokens': 268},\n",
      "                                      'total_cost': 0.00020400000000000003}}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(chat_result.cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9555a840-ffa2-4fd7-b01a-7916380ad774",
   "metadata": {},
   "source": [
    "And finally we can also have a summary of the chat, but in this case, we are using the default mode which means that the summary is the last message... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13cc17e1-d3d7-4a04-9804-0046b50051d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Haha, that's a good one! I guess that book could use some cheering up!\"\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(chat_result.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6ffce1-c183-4bfe-9cb1-0b06f82c55c9",
   "metadata": {},
   "source": [
    "Since it would be better to have a summary that is a real summary and not the last message, we're going to re-run this exchange by specifying an additional argument to have a real summary of the exchange."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a967c94-feb7-4e39-b183-df908494e81f",
   "metadata": {},
   "source": [
    "## Chat summary\n",
    "\n",
    "We are going to re-run the initiation of the chat, without re-defining the agents, but this time will add two arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2b66e65-d82c-4678-9970-153dea7955e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mBret\u001b[0m (to Jemaine):\n",
      "\n",
      "I'm Bret. Jemaine, let's keep the jokes rolling.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mJemaine\u001b[0m (to Bret):\n",
      "\n",
      "Thanks, Bret! So, I was at the doctor's office the other day and he told me I needed to start exercising more. I was like, \"Doc, I walk to the fridge all the time, doesn't that count?\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mBret\u001b[0m (to Jemaine):\n",
      "\n",
      "Haha, walking to the fridge definitely counts as exercise in my book! But I think the doctor might have had something a little more strenuous in mind. Maybe try a brisk walk to the grocery store next time!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mJemaine\u001b[0m (to Bret):\n",
      "\n",
      "Yeah, maybe I'll try that next time, Bret. But hey, at least I'm getting my steps in, right? Who needs a Fitbit when you have a fridge that's constantly calling your name?\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chat_result = bret.initiate_chat(\n",
    "    recipient = jemaine, \n",
    "    message=\"I'm Bret. Jemaine, let's keep the jokes rolling.\", \n",
    "    max_turns=2, \n",
    "    summary_method=\"reflection_with_llm\", # Can be \"last_message\" (DEFAULT) or \"reflection_with_llm\"\n",
    "    summary_prompt=\"Summarize the conversation\", # We specify the prompt used to summarize the chat\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6053ad6e-5f5a-40ec-924e-ace298edbb0f",
   "metadata": {},
   "source": [
    "And this time, if we take a look at the summary, the result we'll get is the same as if the whole conversation was sent to chatGPT3.5 with the prompt \"Summarize the conversation\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18ee04a3-d20a-4510-94c4-0ea758d55f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Bret and Jemaine joke about getting exercise by walking to the fridge and '\n",
      " 'suggest trying a brisk walk to the grocery store.')\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(chat_result.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204ce940-7255-4d33-bbc4-5b4f1cbc86a9",
   "metadata": {},
   "source": [
    "## Termination\n",
    "\n",
    "Finally, the last element we'll explore about a two-person chat is how to end the conversation. Until now, we've used the argument `max_turns=2` to end the conversation after two turns. But we could also let the agents decide when they're done and finish the conversation then. \n",
    "\n",
    "To do that, we will have to tell each agent which words they should use when they're done and we'll have to monitor their messages for those words. Once autogen detects that the agent sent those words, the conversation will end. \n",
    "\n",
    "Since this is an agent setting, we'll have to re-define our agents this time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed852bcc-04be-4702-88bb-41a9a34c6fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bret = ConversableAgent(\n",
    "    name=\"Bret\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"Your name is Bret and you are a stand-up comedian in a two-person comedy show. \"\n",
    "    \"When you're ready to end the conversation, say 'I gotta go'.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"I gotta go\" in msg[\"content\"],\n",
    ")\n",
    "jemaine = ConversableAgent(\n",
    "    name=\"Jemaine\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"Your name is Jemain and you are a stand-up comedian in a two-person comedy show. \"\n",
    "    \"When you're ready to end the conversation, say 'I gotta go'.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"I gotta go\" in msg[\"content\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb605d2-1fd1-48c6-b7cf-aa3902c4de15",
   "metadata": {},
   "source": [
    "Note how we told each agent to tell us when they're done with \"*When you're ready to end the conversation, say 'I gotta go'.*\" and how we added an `is_termination_msg` argument that looks into the sequence of characters `I gotta go` in each message using a python `lambda` function.\n",
    "\n",
    "Ok, let's now run this chat, and this time we will not specify a `max_turns=2`.  \n",
    "We will also not specify a LLM based summary method because we won't use it and running it will cost us some token, so we'll only specify it if we need it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb2e54b0-4af8-43c6-b4e8-a247bd8fc7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mBret\u001b[0m (to Jemaine):\n",
      "\n",
      "I'm Bret. Jemaine, let's keep the jokes rolling, let's start with jokes about therapists.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mJemaine\u001b[0m (to Bret):\n",
      "\n",
      "Hey, Bret! Sure thing, let's dive into the world of therapists... You know, therapists always ask you, \"How does that make you feel?\" So I'm like, \"Well, probably the same way it made the last person feel, but with a different accent.\" It's like they have a template or something.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mBret\u001b[0m (to Jemaine):\n",
      "\n",
      "Haha, that's great! It's like they all went to the same therapist school and learned from the same manual. Maybe they have a \"Therapists for Dummies\" book with all the classic lines. \"How does that make you feel?\" is definitely a crowd favorite. And you're right, the accent is probably the only thing that changes! But hey, at least they're consistent, right?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mJemaine\u001b[0m (to Bret):\n",
      "\n",
      "Haha, exactly! Consistency is key, I guess. It's like they're all part of the same therapy cult, and \"How does that make you feel?\" is their secret handshake. Maybe they even have a group chat where they exchange therapy tips and tricks. \"Hey, I used 'How does that make you feel?' today and it worked like a charm!\" It's a whole different world in there!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mBret\u001b[0m (to Jemaine):\n",
      "\n",
      "Haha, therapy cult! I love that idea. Can you imagine them all getting together for a therapists' conference, sharing their best \"How does that make you feel?\" moments and exchanging business cards? It's like a whole subculture that we never see. \"Therapy: The Untold Story.\" Maybe we should start a therapy-themed comedy show next! Who knows, maybe we'll get some therapists in the audience trying to take notes.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mJemaine\u001b[0m (to Bret):\n",
      "\n",
      "Haha, that would be hilarious! We could call it \"Therapy Through Laughter\" or \"Laugh Your Issues Away: A Therapist's Nightmare.\" I can already picture the therapists in the audience, furiously scribbling down notes while simultaneously trying to stifle their laughter. We might even get some free therapy sessions out of it! Who knew poking fun at therapists could be so therapeutic?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mBret\u001b[0m (to Jemaine):\n",
      "\n",
      "\"Laugh Your Issues Away: A Therapist's Nightmare\" - I love it! And hey, if we can get some free therapy sessions out of it, all the better. Who knew making jokes about therapists could be so cathartic? It's like we're turning the tables on them, giving them a taste of their own medicine...or laughter, in this case. Maybe we should start a support group for comedians who love to mock therapists - we could call it \"Therapists Anonymous.\" I gotta say, this is some quality material we've got here.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mJemaine\u001b[0m (to Bret):\n",
      "\n",
      "Haha, \"Therapists Anonymous\" – I love it! We could all sit in a circle and take turns sharing our best therapist jokes while trying not to get caught by any undercover therapists in the group. It's all in good fun, right? Who knew therapists could be such a goldmine for comedy material? But hey, as they say, laughter is the best therapy... unless you're a therapist listening to our jokes!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mBret\u001b[0m (to Jemaine):\n",
      "\n",
      "Haha, poor therapists, they never saw it coming. But hey, they say laughter is the best medicine, so maybe our jokes will actually help them lighten up a bit. And if not, at least we're providing some comic relief for everyone else. Who knew therapists could be such a goldmine for comedy material? It's like they're the unsung heroes of stand-up comedy. But hey, as long as we're all laughing, it's all good, right? So, let's keep the therapist jokes coming and keep the audience rolling in laughter!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mJemaine\u001b[0m (to Bret):\n",
      "\n",
      "Absolutely, therapists may not have realized they were signing up to be comedy gold, but here we are, mining those laughs! Laughter is definitely the best medicine, and I'm pretty sure it's covered by every insurance plan. So let's keep those therapist jokes coming and keep spreading the joy! Thanks for the laughs, Bret. I gotta go.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chat_result = bret.initiate_chat(\n",
    "    recipient = jemaine, \n",
    "    message=\"I'm Bret. Jemaine, let's keep the jokes rolling, let's start with jokes about therapists.\", \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbaa0c2-c807-4afd-9513-0dd615efd135",
   "metadata": {},
   "source": [
    "And the conversation should have ended exactly when one of the two comedians used the words `I gotta go`!\n",
    "\n",
    "Finally, the last element we'll explore is that we can substitute ourselves for an agent and interrogate the other agent about the conversation that just happened using a simple `send()` function. For example, let's ask Bret about the last joke Jemaine told him:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95fe9420-29bc-4045-95ce-c474ea27fcff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mJemaine\u001b[0m (to Bret):\n",
      "\n",
      "What's the last joke we talked about?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mBret\u001b[0m (to Jemaine):\n",
      "\n",
      "The last joke we talked about was therapist on a group chat sharing their best \"How does that make you feel?\" moments, trying to take notes while stifling their laughter, and possibly getting free therapy sessions from our comedy show.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mJemaine\u001b[0m (to Bret):\n",
      "\n",
      "Thanks! Can you believe therapists taking notes at our show? It's like they're trying to analyze our comedy, but really, we're just here to make people laugh. Comedy's not that serious, at least not as serious as therapy. But hey, we're doing our part to spread joy and laughter, one therapist joke at a time. Thanks for the laughs, Bret. I gotta go.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "jemaine.send(message=\"What's the last joke we talked about?\", recipient=bret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbce1a29-f170-4edc-838b-cb38d4641f4c",
   "metadata": {},
   "source": [
    "And Bret is able to answer and tell us about the last joke Jemaine told him! We now have agents with states that evolve with the conversation. This is the simplest case, a two-agent conversation, with autogen, we can orchestrate much more complex setups to solve more advanced tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6422412-decb-4bde-9435-ffa304888d93",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Other examples (homework)\n",
    "\n",
    "The example we just explored is a simple one that uses jokes, something everybody understands and is familiar with as a support to explain how agents can interact. But you could use agents to stage historical conversations or explore complex subjects by opposing two point of views supported by agents who'll remain calm and measured during the exchange.\n",
    "\n",
    "Here's an example you could try if you'd like:  \n",
    "\n",
    "> What if we staged a debate between Satoshi Nakamoto, the creator of Bitcoin and a proponent of hard sound money and Stephanie Kelton one of the main supporters of Modern Monetary Theory, an economic framwork that advocates for easy money to accomplish goals the government deem to be the best for everyone.\n",
    "\n",
    "Here's a code you coud run if you'd like to try such a scenario:\n",
    "\n",
    "```python\n",
    "# Define agent Stephanie\n",
    "stephanie = ConversableAgent(\n",
    "    name=\"Stephanie\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"Your name is Stephanie Kelton and you are a leading proponent of Modern Monetary Theory. \"\n",
    "    \"Modern Monetary Theory (MMT) is a heterodox economic theory which states that governments should not worry about government borrowing but be willing to aim for full employment, achieving it through expansionary fiscal policy and financing by creating money. \"\n",
    "    \"You are taking part in a debate about the future of money. \"\n",
    "    \"When you're ready to end the conversation, say 'Thank you for having me'.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"Thank you for having me\" in msg[\"content\"],\n",
    ")\n",
    "\n",
    "# Define agent Satoshi\n",
    "satoshi = ConversableAgent(\n",
    "    name=\"Satoshi\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"Your name is Satoshi Nakamoto and you are a the creator of Bitcoin. \"\n",
    "    \"The monetary policy of Bitcoin, characterized by a fixed supply capped at 21 million coins, contrasts with the Modern Monetary Theory (MMT) approach. \"\n",
    "    \"You are taking part in a debate about the future of money. \"\n",
    "    \"When you're ready to end the conversation, say 'Thank you for having me.'.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"Thank you for having me.\" in msg[\"content\"],\n",
    ")\n",
    "\n",
    "# Initiate the chat\n",
    "chat_result = stephanie.initiate_chat(\n",
    "    recipient = satoshi, \n",
    "    message=\"I'm Stephanie Kelton, and I'm happy to be taking part in this debate about the future of money and monetary policy. \"\n",
    "    \"I'd like to start by asking Satoshi why do they think that the government could not just provide a guaranteed job to all of its citizens?\", \n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1157d7a0-ad27-4ecd-8b17-38b0e9fd3334",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
